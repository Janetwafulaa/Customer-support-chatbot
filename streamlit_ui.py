# -*- coding: utf-8 -*-
"""Streamlit UI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hQhrswb99Ks42H_e58o5ZRkLK72pLknA
"""

!pip install langgraph langchain_groq streamlit

#importing libraries

from typing import TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

#defining state class
class State(TypedDict):
    query: str
    category: str
    sentiment: str
    response: str

#Initialize LLM

llm = ChatGroq(
    groq_api_key="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",
    model_name="llama-3.3-70b-versatile",
    temperature=0.7
)

#testing the model
result = llm.invoke("who is William Samoei Ruto?")
result.content

#Helper to run prompts
def run_prompt(template: str, query: str) -> str:
    prompt = ChatPromptTemplate.from_template(template)
    chain = prompt | llm
    return chain.invoke({"query": query}).content

#Node functions
def categorize(state: State) -> State:
    template = (
        "Categorize the following customer query into one of these categories: "
        "Technical, Billing, General. Query: {query}"
    )
    return {"category": run_prompt(template, state["query"])}

def analyze_sentiment(state: State) -> State:
    template = (
        "Analyze the sentiment of the following customer query. "
        "Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}"
    )
    return {"sentiment": run_prompt(template, state["query"])}

def handle_technical(state: State) -> State:
    return {"response": run_prompt("Provide a technical support response to the following query: {query}", state["query"])}

def handle_billing(state: State) -> State:
    return {"response": run_prompt("Provide a billing support response to the following query: {query}", state["query"])}

def handle_general(state: State) -> State:
    return {"response": run_prompt("Provide a general support response to the following query: {query}", state["query"])}

def escalate(state: State) -> State:
    return {"response": "This query has been escalated to a human agent due to its negative sentiment."}

#Router

def route_query(state: State) -> str:
    if state['sentiment'] == 'Negative':
        return "escalate"
    elif state['category'] == 'Technical':
        return "handle_technical"
    elif state['category'] == 'Billing':
        return "handle_billing"
    else:
        return "handle_general"

# Build and compile workflow
workflow = StateGraph(State)
workflow.add_node("categorize", categorize)
workflow.add_node("analyze_sentiment", analyze_sentiment)
workflow.add_node("handle_technical", handle_technical)
workflow.add_node("handle_billing", handle_billing)
workflow.add_node("handle_general", handle_general)
workflow.add_node("escalate", escalate)

workflow.add_edge("categorize", "analyze_sentiment")
workflow.add_conditional_edges("analyze_sentiment", route_query, {
    "handle_technical": "handle_technical",
    "handle_billing": "handle_billing",
    "handle_general": "handle_general",
    "escalate": "escalate",
})
workflow.add_edge("handle_technical", END)
workflow.add_edge("handle_billing", END)
workflow.add_edge("handle_general", END)
workflow.add_edge("escalate", END)

workflow.set_entry_point("categorize")

# Compile the workflow
app = workflow.compile()

# Customer Support Runner
def run_customer_support(query: str) -> dict:
    result = app.invoke({"query": query})
    return {
        "category": result['category'],
        "sentiment": result['sentiment'],
        "response": result['response'],
    }

#testing the output
query = "I want to cancel my subscription before the next billing cycle, Can you help me?"
result = run_customer_support(query)
print(f"Query: {query}")
print(f"Category: {result['category']}")
print(f"Sentiment: {result['sentiment']}")
print(f"Response: {result['response']}")
print("\n")

#streamlit UI
import streamlit as st

st.set_page_config(page_title="Customer Support Chatbot", page_icon="ðŸ¤–")
st.title("ðŸ¤– Customer Support Chatbot (LangGraph + Groq)")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Ask your support question..."):
    # User message
    st.session_state["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Bot response
    with st.chat_message("assistant"):
        result = run_customer_support(prompt)
        response_text = (
            f"**Category:** {result['category']}\n\n"
            f"**Sentiment:** {result['sentiment']}\n\n"
            f"**Response:** {result['response']}"
        )
        st.markdown(response_text)

    st.session_state["messages"].append({"role": "assistant", "content": response_text})